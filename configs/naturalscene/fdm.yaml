model:
  target: image_synthesis.modeling.model.inpainting_model.InpaintingModel
  params:
    mode: 'inpainitng'
    codec_path: ./checkpoint/naturalscene/encoder_decoder.pth
    content_codec_config:
      target: image_synthesis.modeling.codecs.image_codec.patch_vqgan.PatchVQGAN
      params:
        trainable: False
        quantizer_config:
          target: image_synthesis.modeling.codecs.image_codec.vector_quantizer.VectorQuantizer
          params:
            n_e: 1024
            e_dim: 256
            masked_embed_start: 512
            embed_ema: True
            get_embed_type: retrive
            distance_type: euclidean
        encoder_config: 
          target: image_synthesis.modeling.codecs.image_codec.encoder.PatchEncoder
          params:
            in_ch: 3
            res_ch: 256
            out_ch: 256
            stride: 8
        decoder_config:
          target: image_synthesis.modeling.codecs.image_codec.decoder.PatchDecoder
          params:
            in_ch: 256
            out_ch: 3
            res_ch: 256
    fdm_config:
      target: image_synthesis.modeling.modules.FDM.fdm.FDM
      params:
        e_dim: 256
    loss_config:
      target: image_synthesis.modeling.modules.edge_connect.losses.EdgeConnectLoss
      params:
        g_gradient_loss_weight: 0.0
        g_style_loss_weight: 0.0
        g_content_loss_weight: 0.0
        g_adv_loss_weight: 0.0
        
solver:
  base_lr: 0.0
  adjust_lr: none # not adjust lr according to total batch_size
  max_epochs: 100
  save_epochs: 1
  validation_epochs: 1
  sample_unit: epoch
  sample_iterations: 1     # how many iterations to perform sampling once ?
  optimizers_and_schedulers: # a list of configures, so we can config several optimizers and schedulers
  - name: fdm 
    optimizer:
      target: torch.optim.Adam
      params: 
        betas: !!python/tuple [0.0, 0.9]
    scheduler:
      step_iteration: 1
      target: image_synthesis.engine.lr_scheduler.CosineAnnealingLRWithWarmup
      params:
        min_lr: 1.0e-6
        warmup_lr: 2.0e-4 # the lr to be touched after warmup
        warmup: 5000

dataloader:
  data_root: ./data
  batch_size: 16
  num_workers: 6
  train_datasets:
    - target: image_synthesis.data.image_list_dataset_provided_mask.ImageListDataset
      params:
        name: naturalscene/train
        image_end_with: bmp,jpg,jpeg,pgm,png,ppm,tif,tiff,webp,JPEG

        return_data_keys: [image, mask]

        provided_mask_name: irregular-mask

        stroken_mask_params:
          maxVertex: 10
          minVertex: 5
          maxLength: 100
          maxBrushWidth: 30
          minBrushWidth: 10
          keep_ratio: [0.0, 0.5] # [0.3, 0.7]
          min_area: 64 # 8*8 we set the receptive field as the min masked area

        im_preprocessor_config:
          target: image_synthesis.data.utils.image_preprocessor.SimplePreprocessor
          params:
            size: [256, 256]
            smallest_max_size: 288
            random_crop: True
            horizon_flip: True
  validation_datasets:
    - target: image_synthesis.data.image_list_dataset_provided_mask.ImageListDataset
      params:
        name: naturalscene/val
        image_end_with: bmp,jpg,jpeg,pgm,png,ppm,tif,tiff,webp,JPEG

        return_data_keys: [image, mask]

        provided_mask_name: irregular-mask

        stroken_mask_params:
          maxVertex: 10
          minVertex: 5
          maxLength: 100
          maxBrushWidth: 30
          minBrushWidth: 10
          keep_ratio: [0.0, 0.5] # [0.3, 0.7]
          min_area: 64 # 8*8 we set the receptive field as the min masked area
        
        im_preprocessor_config:
          target: image_synthesis.data.utils.image_preprocessor.SimplePreprocessor
          params:
            size: [256, 256]
            smallest_max_size: 256